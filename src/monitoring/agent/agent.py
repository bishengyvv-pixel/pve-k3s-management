from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain.agents.middleware import HumanInTheLoopMiddleware
from langchain_core.messages import AIMessage, ToolMessage
from pydantic import BaseModel
import asyncio
import os
import time
import json
from contextlib import asynccontextmanager
from fastapi import FastAPI, Body
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from typing import Generator, List, Dict, Any, Optional
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()


# --- å…¨å±€å˜é‡ ---
agent_instance = None
mcp_client = None
MONITOR_QUEUES: List[asyncio.Queue] = []

async def broadcast_event(event_data: Dict[str, Any]):
    """å‘æ‰€æœ‰ç›‘æ§å®¢æˆ·ç«¯å¹¿æ’­äº‹ä»¶"""
    for q in MONITOR_QUEUES:
        await q.put(event_data)

class ResponseFormat(BaseModel):
    """ 
    Agentæœ€ç»ˆè¾“å‡ºçš„ç»“æ„ã€‚
    """
    Answer: str 

class ChatRequest(BaseModel):
    message: str
    thread_id: int = 1

def SetAgent(model: str, tools: list, response_format: type, checkpointer: InMemorySaver, system_prompt: str):
    agent = create_agent(
        model=model,
        tools=tools,
        response_format=ToolStrategy(response_format),
        checkpointer=checkpointer,
        system_prompt=system_prompt,
    )
    return agent

async def sse_generator(agent, msg: str, thread_id: int):
    """
    å°† LangGraph çš„è¾“å‡ºè½¬æ¢ä¸º SSE (Server-Sent Events) æ ¼å¼æµã€‚
    """
    print(f"--- æ”¶åˆ°è¯·æ±‚: {msg} (Thread: {thread_id}) ---")
    
    # å¹¿æ’­å¼€å§‹äº‹ä»¶
    await broadcast_event({
        "timestamp": time.time(),
        "thread_id": thread_id,
        "type": "start",
        "content": f"New Request: {msg}"
    })

    # 1. å‘é€å¼€å§‹ä¿¡å·
    yield f"event: start\ndata: å¼€å§‹å¤„ç†...\n\n"

    try:
        async for step in agent.astream(
            {"messages": [{"role": "user", "content": msg}]},
            {"configurable": {"thread_id": thread_id}},
        ):
            for update in step.values():
                
                # 2. å¤„ç†æ¶ˆæ¯ (æ€è€ƒè¿‡ç¨‹)
                if "messages" in update:
                    for message in update["messages"]:
                        # å¤„ç†æ€è€ƒè¿‡ç¨‹ (AIMessage)
                        if isinstance(message, AIMessage) and message.content:
                            # è¿‡æ»¤æ‰æœ€ç»ˆçš„ç»“æ„åŒ–å“åº”åŸå§‹æ–‡æœ¬
                            if message.content.startswith("Returning structured response"):
                                continue

                            # æ„é€  JSON æ•°æ®
                            payload = json.dumps({"type": "thought", "content": message.content}, ensure_ascii=False)
                            yield f"data: {payload}\n\n"
                            
                            # å¹¿æ’­æ€è€ƒäº‹ä»¶
                            await broadcast_event({
                                "timestamp": time.time(),
                                "thread_id": thread_id,
                                "type": "thought",
                                "content": message.content
                            })

                        # å¤„ç†å·¥å…·æ‰§è¡Œç»“æœ (ToolMessage)
                        elif isinstance(message, ToolMessage):
                            payload = json.dumps({
                                "type": "tool_result",
                                "name": message.name,
                                "content": message.content,
                                "tool_call_id": message.tool_call_id
                            }, ensure_ascii=False)
                            yield f"data: {payload}\n\n"

                            # å¹¿æ’­å·¥å…·ç»“æœäº‹ä»¶
                            await broadcast_event({
                                "timestamp": time.time(),
                                "thread_id": thread_id,
                                "type": "tool_result",
                                "name": message.name,
                                "content": message.content,
                                "tool_call_id": message.tool_call_id
                            })

                # 3. å¤„ç†å·¥å…·è°ƒç”¨
                if "tool_calls" in update:
                    for call in update["tool_calls"]:
                        payload = json.dumps({"type": "tool_call", "name": call['name'], "args": call['args']}, ensure_ascii=False)
                        yield f"data: {payload}\n\n"
                        
                        # å¹¿æ’­å·¥å…·è°ƒç”¨äº‹ä»¶
                        await broadcast_event({
                            "timestamp": time.time(),
                            "thread_id": thread_id,
                            "type": "tool_call",
                            "name": call['name'],
                            "args": call['args']
                        })

                # 4. å¤„ç†æœ€ç»ˆç»“æ„åŒ–å“åº”
                if "structured_response" in update:
                    answer = update["structured_response"].Answer
                    payload = json.dumps({"type": "answer", "content": answer}, ensure_ascii=False)
                    yield f"event: result\ndata: {payload}\n\n"
                    
                    # å¹¿æ’­æœ€ç»ˆç­”æ¡ˆäº‹ä»¶
                    await broadcast_event({
                        "timestamp": time.time(),
                        "thread_id": thread_id,
                        "type": "answer",
                        "content": answer
                    })

    except Exception as e:
        error_msg = json.dumps({"type": "error", "content": str(e)}, ensure_ascii=False)
        yield f"event: error\ndata: {error_msg}\n\n"
        
        # å¹¿æ’­é”™è¯¯äº‹ä»¶
        await broadcast_event({
            "timestamp": time.time(),
            "thread_id": thread_id,
            "type": "error",
            "content": str(e)
        })

    # 5. å‘é€ç»“æŸä¿¡å·
    yield "event: done\ndata: [DONE]\n\n"

@asynccontextmanager
async def lifespan(app: FastAPI):
    global agent_instance
    global mcp_client

    DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
    if not DEEPSEEK_API_KEY:
        print("è­¦å‘Šï¼šç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY æœªè®¾ç½®ï¼")
    else:
        os.environ["DEEPSEEK_API_KEY"] = DEEPSEEK_API_KEY
    
    MCP_URL = os.getenv("MCP_URL") 
    os.environ["MCP_URL"] = MCP_URL
    
    print(f"æ­£åœ¨ä½¿ç”¨ MCP URL: {MCP_URL}")
    
    mcp_client = MultiServerMCPClient(
        {
            "pve_tool": {
                "transport": "streamable_http",
                "url": f"{MCP_URL}"
            }
        }
    )
    
    print("æ­£åœ¨è¿æ¥ MCP å·¥å…·...")
    try:
        tools_list = await mcp_client.get_tools()
        print(f"è·å–åˆ°å·¥å…·: {[t.name for t in tools_list]}")
        
        # ä» prompt.txt è¯»å– System Prompt
        try:
            with open("prompt.txt", "r", encoding="utf-8") as f:
                system_prompt = f.read()
        except FileNotFoundError:
             print("è­¦å‘Šï¼šprompt.txt æœªæ‰¾åˆ°ï¼å°†ä½¿ç”¨é»˜è®¤ç©º Promptã€‚")
             system_prompt = "You are a helpful assistant."

        agent_instance = SetAgent(
            model="deepseek-chat",
            tools=tools_list,
            response_format=ResponseFormat,
            checkpointer=InMemorySaver(),
            system_prompt=system_prompt
        )
        print("Agent åˆå§‹åŒ–æˆåŠŸï¼")
    except Exception as e:
        print(f"Agent åˆå§‹åŒ–å¤±è´¥ï¼Œå¯èƒ½æ— æ³•è¿æ¥åˆ° MCP æœåŠ¡ ({MCP_URL})ã€‚é”™è¯¯ä¿¡æ¯: {e}")
    
    yield
    
    print("æœåŠ¡æ­£åœ¨å…³é—­...")

# --- åˆå§‹åŒ– FastAPI ---
app = FastAPI(lifespan=lifespan, title="PVE Agent API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- å®šä¹‰ API ç«¯ç‚¹ ---
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """
    SSE æµå¼å¯¹è¯æ¥å£
    """
    if not agent_instance:
        return JSONResponse({"error": "Agent not initialized. Check server logs for MCP connection failure."}, status_code=503)

    return StreamingResponse(
        sse_generator(agent_instance, request.message, request.thread_id),
        media_type="text/event-stream"
    )

async def monitor_generator(q: asyncio.Queue):
    try:
        while True:
            data = await q.get()
            yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
    except asyncio.CancelledError:
        MONITOR_QUEUES.remove(q)

@app.get("/monitor")
async def monitor_endpoint():
    """
    å®æ—¶ç›‘æ§ SSE æ¥å£
    """
    q = asyncio.Queue()
    MONITOR_QUEUES.append(q)
    return StreamingResponse(monitor_generator(q), media_type="text/event-stream")

async def main():
    print("ğŸš€ å¯åŠ¨ PVE Agent HTTP æœåŠ¡å™¨...")
    print("ğŸ“¡ ç›‘å¬åœ°å€: http://0.0.0.0:9999")
    
    config = uvicorn.Config(app, host="0.0.0.0", port=9999, log_level="info")
    server = uvicorn.Server(config)
    await server.serve()

if __name__ == "__main__":
    asyncio.run(main())
